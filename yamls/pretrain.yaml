# random seed
random_seed: 666

# data precision
precision: float32

# super parameters
start_epoch: 1
epochs: 10
batch_size: 64       # Size of each batch of data
lr: 0.001            # initial Learning Rate
lr_milestones: [100] # milestones where learning rate adjustments occur
weight_decay: 0      # Regularization parameter to prevent overfitting
momentum: 0.9        # Helps accelerate gradients vectors in the right directions, thus leading to faster converging.
num_workers: 4       # Number of subprocesses to use for data loading.
radius: 20           # Parameters (including 5 below) related to data processing and augmentation.
sample_size: 10
max_num_nbr: 12
dmin: 0
step: 0.2
shuffle: true

save_epoch_freq: 1
log_epoch_freq: 1
log_batch_freq: 2

# network architecture
crystal_gnn_config:    # Specifies the graph neural network configuration
  atom_fea_len: 512    # feature length per atom
  n_conv: 3            # number of convolutional layers 
head_output_dim: 2     # The dimensionality of the output space of the head of the network.
drop_rate: 0           # Dropout rate used in the network to prevent overfitting.

# experiment name and path
experiment_name: '0'
continuous_pretrain: false    # Indicates whether the pre-training should continue from a previously saved checkpoint.
pre_ckpt_path: 'checkpoints/pre_checkpoint_{}'

# data path
root_dir: 'data'
processed_dir:
  candidate: 'processed_candidate'
  negative: 'processed_negative'
figs_pretrain: 'figs/pretrain_{}.pdf'
restore_loss: 'out/loss_{}.npy'

# log
log_file: 'logs/pre_out_{}.log'
